{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744ee155-e0f1-4a45-b21c-32d5cd7ba369",
   "metadata": {},
   "source": [
    "Download the data and create a well-structured notebook with Markdown headings and notes that describes your process as you:\n",
    "\n",
    "Load the data\n",
    "Perform some lightweight exploratory data analysis\n",
    "Create train/test splits from the data\n",
    "Fit at least 5 (but hopefully more) different classification model forms to the train split\n",
    "Score all fitted models on your test split (using at least an F1 score)\n",
    "Record the best performing regression model in your model selection\n",
    "Models to try:\n",
    "\n",
    "kNN\n",
    "Naive Bayes\n",
    "SVMs\n",
    "Logistic Regression\n",
    "DecisionTree\n",
    "RandomForrest\n",
    "GradientBoosting\n",
    "AdaBoost\n",
    "Multilayer Perceptron\n",
    "Voting Ensemble\n",
    "Stacking Ensemble\n",
    "Ridge Classifier\n",
    "LASSO Classifier\n",
    "Make sure you do at least a little bit of hyper parameter tuning! \n",
    "\n",
    "*Prereq download https://archive.ics.uci.edu/static/public/73/mushroom.zip\n",
    "and rename agaricus-lepiota.data to agaricus-lepiota.data.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766ea09a-5cc3-4b35-a691-6a15b6f88aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d997595f-7b32-4cc7-a4f1-72a2f2c52faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the data after renaming mushroom/agaricus-lepiota.data to mushroom/agaricus-lepiota.data.txt export to new df\n",
    "\n",
    "raw_df = pd.read_csv (r'mushroom/agaricus-lepiota.data.txt')\n",
    "raw_df.to_csv (r'rawmushroom.csv', index=None)\n",
    "\n",
    "data = raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27980b4a-d5f5-4c39-a524-b5ad33b95e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8123, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform some lightweight exploratory data analysis\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6b6bd9-05b9-4243-8ce8-7954cb4d8d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       p  x  s  n  t p.1  f  c n.1  k  ... s.2  w w.1 p.2 w.2  o p.3 k.1 s.3  u\n",
       "0     e  x  s  y  t   a  f  c   b  k  ...   s  w   w   p   w  o   p   n   n  g\n",
       "1     e  b  s  w  t   l  f  c   b  n  ...   s  w   w   p   w  o   p   n   n  m\n",
       "2     p  x  y  w  t   p  f  c   n  n  ...   s  w   w   p   w  o   p   k   s  u\n",
       "3     e  x  s  g  f   n  f  w   b  k  ...   s  w   w   p   w  o   e   n   a  g\n",
       "4     e  x  y  y  t   a  f  c   b  n  ...   s  w   w   p   w  o   p   k   n  g\n",
       "...  .. .. .. .. ..  .. .. ..  .. ..  ...  .. ..  ..  ..  .. ..  ..  ..  .. ..\n",
       "8118  e  k  s  n  f   n  a  c   b  y  ...   s  o   o   p   o  o   p   b   c  l\n",
       "8119  e  x  s  n  f   n  a  c   b  y  ...   s  o   o   p   n  o   p   b   v  l\n",
       "8120  e  f  s  n  f   n  a  c   b  n  ...   s  o   o   p   o  o   p   b   c  l\n",
       "8121  p  k  y  n  f   y  f  c   n  b  ...   k  w   w   p   w  o   e   w   v  l\n",
       "8122  e  x  s  n  f   n  a  c   b  y  ...   s  o   o   p   o  o   p   o   c  l\n",
       "\n",
       "[8123 rows x 23 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4249c5-a948-4225-9d76-13cc18c61639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>s</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>p.1</th>\n",
       "      <th>f</th>\n",
       "      <th>c</th>\n",
       "      <th>n.1</th>\n",
       "      <th>k</th>\n",
       "      <th>...</th>\n",
       "      <th>s.2</th>\n",
       "      <th>w</th>\n",
       "      <th>w.1</th>\n",
       "      <th>p.2</th>\n",
       "      <th>w.2</th>\n",
       "      <th>o</th>\n",
       "      <th>p.3</th>\n",
       "      <th>k.1</th>\n",
       "      <th>s.3</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>...</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "      <td>8123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3655</td>\n",
       "      <td>3244</td>\n",
       "      <td>2283</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7913</td>\n",
       "      <td>6811</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>...</td>\n",
       "      <td>4935</td>\n",
       "      <td>4463</td>\n",
       "      <td>4383</td>\n",
       "      <td>8123</td>\n",
       "      <td>7923</td>\n",
       "      <td>7487</td>\n",
       "      <td>3967</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           p     x     s     n     t   p.1     f     c   n.1     k  ...   s.2  \\\n",
       "count   8123  8123  8123  8123  8123  8123  8123  8123  8123  8123  ...  8123   \n",
       "unique     2     6     4    10     2     9     2     2     2    12  ...     4   \n",
       "top        e     x     y     n     f     n     f     c     b     b  ...     s   \n",
       "freq    4208  3655  3244  2283  4748  3528  7913  6811  5612  1728  ...  4935   \n",
       "\n",
       "           w   w.1   p.2   w.2     o   p.3   k.1   s.3     u  \n",
       "count   8123  8123  8123  8123  8123  8123  8123  8123  8123  \n",
       "unique     9     9     1     4     3     5     9     6     7  \n",
       "top        w     w     p     w     o     p     w     v     d  \n",
       "freq    4463  4383  8123  7923  7487  3967  2388  4040  3148  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6c00f5-8a47-4672-9d4d-c84a3ecf0663",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8123 entries, 0 to 8122\n",
      "Data columns (total 23 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   p       8123 non-null   object\n",
      " 1   x       8123 non-null   object\n",
      " 2   s       8123 non-null   object\n",
      " 3   n       8123 non-null   object\n",
      " 4   t       8123 non-null   object\n",
      " 5   p.1     8123 non-null   object\n",
      " 6   f       8123 non-null   object\n",
      " 7   c       8123 non-null   object\n",
      " 8   n.1     8123 non-null   object\n",
      " 9   k       8123 non-null   object\n",
      " 10  e       8123 non-null   object\n",
      " 11  e.1     8123 non-null   object\n",
      " 12  s.1     8123 non-null   object\n",
      " 13  s.2     8123 non-null   object\n",
      " 14  w       8123 non-null   object\n",
      " 15  w.1     8123 non-null   object\n",
      " 16  p.2     8123 non-null   object\n",
      " 17  w.2     8123 non-null   object\n",
      " 18  o       8123 non-null   object\n",
      " 19  p.3     8123 non-null   object\n",
      " 20  k.1     8123 non-null   object\n",
      " 21  s.3     8123 non-null   object\n",
      " 22  u       8123 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "\n",
      "Check null sum\n",
      "p      0\n",
      "x      0\n",
      "s      0\n",
      "n      0\n",
      "t      0\n",
      "p.1    0\n",
      "f      0\n",
      "c      0\n",
      "n.1    0\n",
      "k      0\n",
      "e      0\n",
      "e.1    0\n",
      "s.1    0\n",
      "s.2    0\n",
      "w      0\n",
      "w.1    0\n",
      "p.2    0\n",
      "w.2    0\n",
      "o      0\n",
      "p.3    0\n",
      "k.1    0\n",
      "s.3    0\n",
      "u      0\n",
      "dtype: int64\n",
      "\n",
      "Distribution\n",
      "p\n",
      "e    4208\n",
      "p    3915\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Display basic information about the dataset\n",
    "\n",
    "print(\"\\nInfo\")\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nCheck null sum\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Distribution of the target variable\n",
    "print(\"\\nDistribution\")\n",
    "print(data.iloc[:, 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e28a6b4-126a-4b76-8000-5835528bb43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6498, 22), (1625, 22), (6498,), (1625,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Splitting the data\n",
    "X = data.drop('p', axis=1)\n",
    "y = data['p']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape of the training and test sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd2a512-2a62-4740-bd32-a99ac3036d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawnadmin/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': 0.9538475555137003,\n",
       " 'DecisionTree': 1.0,\n",
       " 'RandomForest': 1.0,\n",
       " 'SVM': 0.9883002885717984,\n",
       " 'KNN': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Fit models and calculate F1 score\n",
    "scores = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores[name] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the F1 scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d0e1d-440c-487e-8a0e-017de0663061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Observations:\n",
    "The Decision Tree, Random Forest, and KNN models achieved a perfect F1 score of 1.0, indicating extremely high performance on this dataset.\n",
    "Logistic Regression and SVM also performed well but with slightly lower scores. Even with a vetted dataset such as this, I am skeptical of these results.\n",
    "\n",
    "Additional Considerations:\n",
    "While perfect scores may indicate excellent model performance, it's also important to consider the possibility of overfitting, especially with models like Decision Trees.\n",
    "In practice, you might want to perform additional validation, like cross-validation, or inspect other metrics depending on the specific requirements of your task.\n",
    "This concludes the task with the selected dataset. You now have an overview of the process of loading data, performing EDA, preprocessing, training multiple models, and evaluating them based on the F1 score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ccf759-9d92-4738-a167-ddf582c93fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': 0.94891112674963,\n",
       " 'DecisionTree': 0.9760090127373192,\n",
       " 'RandomForest': 0.9876828561596037,\n",
       " 'SVM': 0.9883002885717984,\n",
       " 'KNN': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting hyperparameters for each model\n",
    "\n",
    "# Updated models with new hyperparameters\n",
    "updated_models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, C=0.5, solver='liblinear'),\n",
    "    'DecisionTree': DecisionTreeClassifier(max_depth=5, min_samples_split=4),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=5),\n",
    "    'SVM': SVC(C=1, kernel='rbf'),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "}\n",
    "\n",
    "# Fit models and evaluate\n",
    "updated_model_scores = {}\n",
    "for name, model in updated_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    updated_model_scores[name] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "updated_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e495ec-3e8d-4976-85cc-494568bbe624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Observations:\n",
    "The KNN model maintains a perfect F1 score of 1.0.\n",
    "Random Forest and SVM show very high F1 scores, indicating strong performance.\n",
    "Decision Tree and Logistic Regression have slightly lower scores compared to the others, but they still perform well.\n",
    "Still skpetical of these perfect or near perfect scores. Maybe this dataset lends itself to easy classificaion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97860a9a-6412-4938-9c14-cbfc01adcf3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     43\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> 44\u001b[0m     final_model_scores[name] \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m final_model_scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1239\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1098\u001b[0m ):\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1240\u001b[0m         y_true,\n\u001b[1;32m   1241\u001b[0m         y_pred,\n\u001b[1;32m   1242\u001b[0m         beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1243\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1244\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   1245\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   1246\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1247\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   1248\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1413\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1252\u001b[0m     {\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1281\u001b[0m ):\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1414\u001b[0m         y_true,\n\u001b[1;32m   1415\u001b[0m         y_pred,\n\u001b[1;32m   1416\u001b[0m         beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m   1417\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1418\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   1419\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   1420\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-score\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m   1421\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1422\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   1423\u001b[0m     )\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1724\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \n\u001b[1;32m   1568\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1724\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1501\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1501\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I couldn't get this to work after playing around with it for a while. This is the Error I got > ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
    "\n",
    "\"\"\"\n",
    "# Initialize individual models\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Initialize Voting and Stacking Ensembles using the individual models\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', logistic_model), \n",
    "        ('random_forest', random_forest_model)\n",
    "    ], voting='hard')\n",
    "\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', logistic_model), \n",
    "        ('random_forest', random_forest_model)\n",
    "    ], final_estimator=LogisticRegression())\n",
    "\n",
    "# Initialize MLP, Ridge, and LASSO models\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "ridge = RidgeClassifier()\n",
    "lasso = make_pipeline(StandardScaler(), Lasso())\n",
    "\n",
    "# Dictionary of all models\n",
    "all_models = {\n",
    "    'LogisticRegression': logistic_model,\n",
    "    'RandomForest': random_forest_model,\n",
    "    'MLP': mlp,\n",
    "    'VotingEnsemble': voting_ensemble,\n",
    "    'StackingEnsemble': stacking_ensemble,\n",
    "    'RidgeClassifier': ridge,\n",
    "    'LASSO': lasso\n",
    "}\n",
    "\n",
    "# Fit and score models\n",
    "final_model_scores = {}\n",
    "for name, model in all_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    final_model_scores[name] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "final_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93310ad6-c264-42bc-b880-1f327790af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize individual models\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Initialize Voting and Stacking Ensembles using the individual models\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', logistic_model), \n",
    "        ('random_forest', random_forest_model)\n",
    "    ], voting='hard')\n",
    "\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', logistic_model), \n",
    "        ('random_forest', random_forest_model)\n",
    "    ], final_estimator=LogisticRegression())\n",
    "\n",
    "# Initialize MLP, Ridge, and LASSO models\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "ridge = RidgeClassifier()\n",
    "lasso = make_pipeline(StandardScaler(), Lasso())\n",
    "\n",
    "# Dictionary of all models\n",
    "all_models = {\n",
    "    'LogisticRegression': logistic_model,\n",
    "    'RandomForest': random_forest_model,\n",
    "    'MLP': mlp,\n",
    "    'VotingEnsemble': voting_ensemble,\n",
    "    'StackingEnsemble': stacking_ensemble,\n",
    "    'RidgeClassifier': ridge,\n",
    "    'LASSO': lasso\n",
    "}\n",
    "\n",
    "# Fit and score models\n",
    "model_scores = {}\n",
    "for name, model in all_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_scores[name] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52dd7d1-9b16-45a8-9c1e-b529080a10d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
