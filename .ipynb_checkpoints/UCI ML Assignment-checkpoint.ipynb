{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e168dfa",
   "metadata": {},
   "source": [
    "# Communities and Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43f32c",
   "metadata": {},
   "source": [
    "## Notebook Setup and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee31fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV, LassoCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.features import RadViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf237909",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'communities.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mdf = pd.read_csv('/kaggle/input/crime-data/communities.data')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mwith open('/kaggle/input/crime-data/communities.names', 'r') as file:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mprint(file_contents)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Reading files if communities.data in same directory as notebook\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommunities.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunities.names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     13\u001b[0m     file_contents \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'communities.data'"
     ]
    }
   ],
   "source": [
    "#How Emily read files\n",
    "\"\"\" \n",
    "df = pd.read_csv('/kaggle/input/crime-data/communities.data')\n",
    "with open('/kaggle/input/crime-data/communities.names', 'r') as file:\n",
    "    file_contents = file.read()\n",
    "\n",
    "print(file_contents)\n",
    "\"\"\"\n",
    "\n",
    "#Reading files if communities.data in same directory as notebook\n",
    "df = pd.read_csv('communities.data')\n",
    "with open('communities.names', 'r') as file:\n",
    "    file_contents = file.read()\n",
    "\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd085e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "#No headers. Nothing to identify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e262db8",
   "metadata": {},
   "source": [
    "#### Assigning Column Names to Communities Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract column names from the communities.names file\n",
    "\n",
    "def extract_column_names(filename):\n",
    "    \"\"\"\n",
    "    Extracts column names from a file where each column name is prefixed with '@attribute'\n",
    "    \"\"\"\n",
    "    column_names = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('@attribute'):\n",
    "                # Extract the attribute name\n",
    "                parts = line.split()\n",
    "                if len(parts) > 1:\n",
    "                    column_name = parts[1]\n",
    "                    column_names.append(column_name)\n",
    "    return column_names\n",
    "\n",
    "column_names = extract_column_names('/kaggle/input/crime-data/communities.names')\n",
    "\n",
    "df.columns = column_names                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbca31",
   "metadata": {},
   "source": [
    "#### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a296b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace '?' with NaN\n",
    "df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data types specified in communities.names file under \"Attribute Information\" section \n",
    "# List of columns not to convert\n",
    "columns_not_to_convert = ['state', 'county', 'community', 'communityname', 'fold','LemasGangUnitDeploy']\n",
    "\n",
    "# Converting all other columns to float64 so can be used for analysis \n",
    "for column in df.columns:\n",
    "    if column not in columns_not_to_convert:\n",
    "        df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No duplicates\n",
    "duplicate_rows = df.duplicated()\n",
    "df[duplicate_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]\n",
    "\n",
    "#Drop columns with a high number of missing values\n",
    "high_missing_cols = missing_values[missing_values > 1000].index\n",
    "df_cleaned = df.drop(columns=high_missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the column with only one missing value, fill it with the median\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "df_cleaned['OtherPerCap'] = median_imputer.fit_transform(df_cleaned[['OtherPerCap']])\n",
    "\n",
    "# Check for any categorical columns remaining\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Since 'communityname' is a categorical column that likely has a high cardinality, \n",
    "# it might not be useful for the model, so we drop it.\n",
    "df_cleaned.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_cleaned.drop(columns=['ViolentCrimesPerPop'], axis=1)\n",
    "y = df_cleaned['ViolentCrimesPerPop']\n",
    "\n",
    "#Show list of features, Target = ViolentCrimesPerPop'\n",
    "feature_names = X.columns.tolist()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f00656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ab911",
   "metadata": {},
   "source": [
    "#### Create Train/Test Splits From Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Output the shape of the resulting dataframes\n",
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14850e",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b410a3c8",
   "metadata": {},
   "source": [
    "#### General Statistical Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b386ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at basic stats for each column used for prediction. Excludes columns that are only descriptive\n",
    "df.drop(columns=['state', 'fold']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a boxplot to look at distrubtion of violent crime for each state\n",
    "\n",
    "plt.figure(figsize=(15, 10))  # Adjust the size of the plot as needed\n",
    "sns.boxplot(x='state', y='ViolentCrimesPerPop', data=df)\n",
    "\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Violent Crimes Per Population')\n",
    "plt.title('Distribution of Violent Crimes Per Population by State')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5238e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data seems to skip some states. Maybe uses territories. Otherwise unsure why states go up to 56\n",
    "unique_states = df['state'].unique()\n",
    "print(sorted(unique_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a boxplot to look at distrubtion of violent crime for each county.\n",
    "#Needs tinkering to plot size and label size to better visualize the data. \n",
    "\n",
    "plt.figure(figsize=(100, 30))  # Adjust the size of the plot as needed\n",
    "sns.boxplot(x='county', y='ViolentCrimesPerPop', data=df)\n",
    "\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Violent Crimes Per Population')\n",
    "plt.title('Distribution of Violent Crimes Per Population by State')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate correlation coefficients between all variables and violent crime\n",
    "\n",
    "# Select only columns of float64 type. Will only use non descriptive data.\n",
    "float_columns = df.select_dtypes(include=['float64'])\n",
    "\n",
    "correlation_matrix = float_columns.corr()\n",
    "\n",
    "# Extract correlations with 'ViolentCrimesPerPop'\n",
    "violent_crimes_correlation = correlation_matrix['ViolentCrimesPerPop']\n",
    "\n",
    "print(violent_crimes_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a36d1",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c24cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_cleaned.corr().abs()\n",
    "corr_matrix\n",
    "high_corr_var=np.where(corr_matrix>0.8)\n",
    "high_corr_var=[(corr_matrix.index[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "print(\"Features that are highly correlated with each other:\")\n",
    "high_corr_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fa106",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def remove_collinear_features(x, threshold):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = X.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                \n",
    "            #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    X = X.drop(columns=drops)\n",
    "    print('Removed Columns {}'.format(drops))\n",
    "    return X\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d366e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(\"Removing Correlated Features\")\n",
    "# Pass DataFrame and Threshold value \n",
    "remove_collinear_features(X_train,0.80)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a711fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the correlations based on their absolute values in order of strongest correlations\n",
    "# Need to drop ViolentCrimesPerPop\n",
    "violent_crimes_correlation.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15a325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:37:09.059387Z",
     "iopub.status.busy": "2023-12-19T23:37:09.059063Z",
     "iopub.status.idle": "2023-12-19T23:37:09.065121Z",
     "shell.execute_reply": "2023-12-19T23:37:09.064166Z",
     "shell.execute_reply.started": "2023-12-19T23:37:09.059365Z"
    }
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='ViolentCrimesPerPop', data=df)\n",
    "\n",
    "# My initial attempt to explain the results: \n",
    "# Boxplot shows the 'ViolentCrimesPerPop' distribution, with a median of 0.2 and the middle 50% of data between the 25th and 75th percentiles.\n",
    "# Outliers are present above the upper whisker, suggesting a right-skewed distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.scatter(x=\"PctKids2Par\", y=\"ViolentCrimesPerPop\", data=correlation_matrix, c='orange')\n",
    "ax2.scatter(x=\"PctIlleg\", y=\"ViolentCrimesPerPop\", data=correlation_matrix, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d7a7c",
   "metadata": {},
   "source": [
    "#### Linear Regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "# My initial attempt to explain the results: \n",
    "# R-squared of 0.657 indicates that the model explains about 65.7% of the variance in 'ViolentCrimesPerPop', indicating a moderate to good fit. \n",
    "#The Mean Squared Error of 0.019 suggests the model's predictions are relatively close to actual values, indicating a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33ff90",
   "metadata": {},
   "source": [
    "##### L2 and L1 Regularization for Ridge (L2) and Lasso (L1) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 and L1 Regularization \n",
    "alphas = np.logspace(-10, 0, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a34faa",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2667b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV \n",
    "\n",
    "model = RidgeCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.alpha_))\n",
    "\n",
    "# My initial attempt to explain the results: \n",
    "# #Alpha of 1.000 shows a good balance between complexity and prediction accuracy, #explaining 66.4% of the variance and achieving a low mean squared error of 0.018, indicating effective predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV \n",
    "\n",
    "model = LassoCV(alphas=alphas, max_iter=10000) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1538b",
   "metadata": {},
   "source": [
    "#### Elastic Net Model\n",
    "- expands regression to penalize complexity and minimize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456eb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "model = ElasticNetCV(alphas=alphas, max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54905861",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffe3de",
   "metadata": {},
   "source": [
    "Ideally, the datapoints should be randomly distributed around the horizontal axis and there shouldn't be any pattern. This suggests a on-linear model may be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4a662",
   "metadata": {},
   "source": [
    "Random Forest Regressor achieves a worse R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('ridge', RidgeCV(alphas=alphas)),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['ridge'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(3)), \n",
    "    ('ridge', RidgeCV(alphas=alphas)),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['ridge'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c119b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = AdaBoostRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "model = BayesianRidge() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f553c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(5)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e2bb95",
   "metadata": {},
   "source": [
    "None of these models are performing particularly well. We may need to be more selective in our features or treat outliers in order to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(df):\n",
    " u = np.mean(df_cleaned['ViolentCrimesPerPop'])\n",
    " s = np.std(df_cleaned['ViolentCrimesPerPop'])\n",
    " df_filtered = df_cleaned[(df_cleaned['ViolentCrimesPerPop']>(u-2*s)) & (df_cleaned['ViolentCrimesPerPop']<(u+2*s))]\n",
    " return df_filtered\n",
    "\n",
    "df=reject_outliers(df)\n",
    "X = df.drop(columns=['ViolentCrimesPerPop'], axis=1)\n",
    "y = df['ViolentCrimesPerPop']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b02234",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eede2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Output the shape of the resulting dataframes\n",
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad42deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV \n",
    "\n",
    "model = LassoCV(alphas=alphas, max_iter=10000) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers seems to have lowered the r2 score-- maybe simply because we reduced the amount of data?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4188713,
     "sourceId": 7233662,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
